
들어가기 앞서 처음 진행해본 공모전이었음에도 불구하고 너무 좋은 팀원들을 많나 많은 경험을 쌓고 공부할 수 있었음 팀원 분들과 이런 프로그램을 진행해준 LG사에도 정말 감사했습니다.

추가로 시각화와 데이터 탐색은 조금 더 익숙하고 편하다 생각하는 R에서 진행을 하고 모델링과 전처리는 팀원 분들과의 소통과 프로젝트 조건을 고려하여 파이썬으로 진행하였습니다. 

프로젝트의 내용을 모두 다루는 것보다 사용한 방법들을 대표적으로 보여줄 수 있는 하나에서 두 개의 예만을 넣어 가독성을 살리고자 했습니다.

# 1. 팀 프로젝트로서의 경험
## 1.1 느낀점 간단 요약

1. 팀원들과 아이디어를 교환하고, 팀원들의 테스트와 결과를 보면서 아직 시도하지 않은 방향으로 실험을 진행하는 것이 좋겠다.
2. 프로젝트 진행이 매끄럽게 잘 진행되도록 하는 것도 중요하지만 주마다 진행되는 회의 등을 기준으로 뒤쳐지고 있는 팀원은 없는지 확인하는 것이 중요하다.
3. 실험의 결과가 긍정적이지 못할 수도 있고, 무엇을 해야할지 모를 수도 있다. 다만 중요한 것은 적극적인 자세를 유지해야 한다.
4. 팀원들의 의견에 내가 알고 있는 영역 내에서 부정적이더라도 일단 시도해보는 것이 좋다. 예전 고 스티브 잡스의 서적을 읽은 적이 있었는데 많이 공감 되었다. 나의 경험이 절대적이지 않으며 팀원들의 시도 속에서 좋은 결과가 나올 수 있다. 좋은 결과가 나오지 않더라도 이러한 시도들은 나와 팀원들의 실력을 올려줄 것이기에 장기적으로 긍정적이다.



# 2. 데이터 EDA

기본적으로 이번 LG Aimers는 결측치가 매우 많은 feature들이 존재하였으며 범주형 변수들에는 의미 없는 세부 범주가 많이 존재하는 등 책의 예제나 이전에 보았던 다른 데이터들과는 다르다는 느낌을 받았다. 따라서 EDA 과정에서는 다음의 두 가지 문제를 핵심적으로 다루어야 한다고 생각하였다.

###### 1. 결측치가 너무 많다.
   - 삭제를 진행할 경우 소실되는 데이터가 너무 많아 다른 방법을 고안해야 한다.
   - 당연히 모델 학습에 악영향을 준다.

###### 2. 범주 변수에 너무 쓸모없는 범주들이 많다.
   - 세부 범주를 처리해 주지 않는다면 과적합의 문제가 생긴다.
   - 반대로 세부 범주를 잘못 처리하면 과소적합의 문제가 생긴다.

위의 두 가지 문제를 처리하는 것이 EDA 단계에서의 핵심이라 판단하였다. (+ 파생변수 생성은 뒤에서 다루기)


## 2.1 데이터 탐색(EDA)

###### 1. EDA 당시 진행한 시각화 Github 링크 (R)
   https://github.com/LWH4Data/Projects/blob/main/LG%20Aimers%204%EA%B8%B0/EDA%20%EC%8B%9C%EA%B0%81%ED%99%94.R
###### 2. EDA 결과 작성 ppt
![[EDA.pptx]]


### 2.1.1 결측치

![[Pasted image 20240310050504.png|750]]
R로 원본 데이터를 시각화한 결과 결측치가 매우 많은 feature들이 존재한다. 수치형 변수의 결측치 처리는 다음의 방식으로 진행하였다.

###### 1. it_strategic_ver / id_strategic_ver / idit_strategic_ver
   - 가중치 feature 이다. it_strategic_ver은 사업 영역이 it인 경우 1, 그렇지 않으면 0이기에 결측치를 사업 영역 별로 채워 준다. id_strategic_ver 또한 동일한 방법으로 결측치를 해결해 준다. 
   - idit_strategic_ver의 경우 두 feature 모두 1인 경우 1, 그렇지 않으면 0을 갖기에 두 변수의 값을 고려하여 결측치를 처리해 주었다.
###### 2. historical_existing_cnt / ver_win_ratio_per_bu / ver_win_rate_x
위의 변수 중 historical_exsting_cnt는 사업 전환 시도 횟수로 int type 이다. 나머지 feature들은 모두 비율을 값으로 갖는다. 결국 모두 수치형 변수이기에 결측치를 모두 0으로 처리하였다.
###### 3. com_reg_ver_win_rate
해당 변수의 경우 특정 부서 별로 계산된 영업 전환 비율이다. 이 변수의 경우 부서 별로 최빈값을 통해 결측치를 처리해 주었다. 다만 이 과정에서 최빈값을 사용해도 될 것인가 고민이 있었다(팀원 분의 테스트로 성능 향상이 확인되었다).

> - 긍정적 기대 : 많은 결측치를 다른 변수의 정보를 통해 처리 했기에 모델에 추가적인 정보를 제공하여 모델에 긍정적인 결과를 만들 수 있다.
> - 부정적 우려 : 너무 많은 결측치가 존재하기에 다른 변수를 통해 결측치를 처리하는 것이 자칫 과적합이 발생할 우려가 있다.

결론적으로 com_reg_ver_win_rate의 경우 위에서 언급한 것과 같이 최빈값으로 결측치를 처리하였을 때 모델의 성능이 소폭 향상 되었다. 또한 모델에 관해서는 후술하지만 Tree 모델을 사용하기에 크게 문제가 될 것은 없다 생각되어 com_reg_ver_win_rate 변수만 최빈값으로 결측치를 처리해 주었다.


### 2.1.2 세부 범주
대표적으로 세부 범주가 너무 많은 경우의 feature를 보이면 다음과 같다. 

![[Pasted image 20240310051438.png|500]]

###### 위는 고객들의 국가와 도시에 관한 feature인데 다음의 문제가 있다.
- 일부 범주를 제외하고는 너무 세부 범주가 많다. 
- 더하여 오타로 인한 잘못된 범주까지 포함하고 있다. 
- 마지막으로 국가 정보와 도시 정보를 '/'로 구분하여 포괄하고 있기에 text 데이터 또한 처리가 필요하다. 데이터 셋에는 위와 같은 범주형 변수가 정말 많았다.

위와 같은 데이터의 세부 범주를 모두 삭제할 경우 너무 많은 데이터가  소실된다. 따라서 고민이 많았는데 팀원 분이 도메인을 활용하여 데이터를 모두 처리해 주셨다. 대표적인 예를 들면 다음 두 가지가 있다.

###### 1. 국가 데이터의 경우 '/'을 기준으로 분류를 하여 국가 데이터만 추출, 이후 필요한 범주에 한하여 직접 확인을 하며 각 국가에 직접 매핑을 하였다.
###### 2. 너무 세부적인 경우(범주의 빈도가 3~10 등) 해당 데이터는 삭제를 하는 방법을 활용하였다. 
###### 3. 위의 경우를 대표적으로 보여주는 feature의 전처리는 다음과 같다. 
![[Pasted image 20240310052617.png]]
위는 LG의 영업 지사별(국가) 데이터이다. 해당 feature를 처리할 때 직접 LG 영업사의 사이트에 들어가 법인명을 확인하며 매핑을 진행하였으며 따라서 좌측에서 우측의 그림대로 feature에 존재하는 범주들을 축소할 수 있었다. 

다른 범주형 feature들 또한 위와 동일하게 도메인을 통해 세부 범주를 처리하였으며 이 과정에서 모델의 성능이 0.5점 대에서 0.6점대로 꾸준히 상승할 수 있었다.


### 2.1.3 EDA 정리
###### 1. 데이터의 내부 도메인 통해 수치형 변수의 결측치 처리 
(it_strategic_ver / id_strategic_ver / idit_strategic_ver)
###### 2. 수치형 데이터의 경우 0으로 처리
(historical_existing_cnt / com_reg_ver_win_rate / ver_win_ratio_per_bu / ver_win_rate_x)
###### 3. 범주형 변수는 도메인을 적극 활용



# 3. 언더 샘플링과 파생변수 생성

## 3.1 언더 샘플링

우선 주어진 데이터 셋의 target 변수는 심하게 imbalanced 되어 있었다. 아래 시각 자료를 참고하면 쉽게 확인할 수 있다. 

![[Pasted image 20240312060751.png|description|center|700x400]]
들어가기 앞서 우리 팀이 imbalaced target 변수를 위해 취한 방법들은 다음과 같다.
- over sampling
- 모델의 인자에 class_weight를 dictionary로 입력(1 : 20)
- under sampling (본문에서 다루는 주제)

### 3.1.1 성능이 향상된 이유에 대한 개인적인 생각과 느낀점
Tree model의 경우 imbalaced한 경우에도 모델이 강건하다. 또한 정보를 찾아본 결과 over sampling의 경우 Tree 모델에서 성능 개선에는 큰 차이가 없었으나 under sampling의 경우 오히려 성능이 하락 되는 결과가 나오는 것으로 확인되었다. 위와 같은 이유로 개인적으로는 Tree 모델을 사용할 것이기에 imbalace 문제점은 고려 우선 순위가 낮다고 판단하여 생각을 미루고 있었다.

그러나 팀원 분이 target = false인 데이터를 추출하고 row 별로 결측치가 일정 비율(코드에서는 0.3, 즉 30%)이상인 row들을 삭제하여 under sampling을 진행하셨고 결과적으로 모델의 성능이 소폭 향상되는 것을 확인할 수 있었다. 

###### *<target = false 이면서 row 별로 결측치가 30% 이상인 row 삭제 로직>*
![[Pasted image 20240312063953.png]]

처음 위의 결과를 확인했을 때 under sampling이 효과가 없을 것이라 생각하고 있던 나에게는 상당히 충격적인 결과였다. 지금에서 다시 생각을 정리하면 다음과 같다.

> Imbalaced target의 문제가 해결된 것은 아니며 아마도 결측치가 너무 많아 학습에 부정적인 영향을 주는 데이터(row)을 삭제하여 모델의 성능이 개선 되었다.

###### 위와 같이 생각하게 된 이유는 다음의 그림을 확인하면 이해할 수 있다. 
![[Pasted image 20240312062407.png|700]]
- 좌측 : 원본 데이터의 target 비율 / 우측 : 전처리 후 최종 target 비율
- 비율로 보았을 때 imbalance가 해결되었다고 보기는 어렵다.

위에서 기술한 것과 같이 imbalace 문제가 해결되었다고 보기에는 비율 차이는 크게 존재하지 않는다. 그렇다면 남은 것은 결측치가 너무 많은 row를 제거한 것이 성능을 개선하게 된 주된 이유가 된다.

> 가장 인상 깊었던 것은 어느 정도 정해진 방법들은 있지만 주어지는 데이터 셋 등 상황이 매번 다르기 때문에 어떤 방법이 되었던 시도해 보는 것이 일단 좋다는 생각을 하게 되었다. 
> 
> 특히 나의 경우 많은 정보를 찾아보고 가설을 세운 뒤 실험을 하는 것에 집중을 하였는데 팀원 중 한 분은 많은 시도를 하면서 위와 같은 방법을 찾아내는 것을 보니 공부를 많이 하는 것 만큼이나 여러 시도를 해보아야 한다는 것을 체감할 수 있었다.



## 3.2 파생변수 생성
### 3.2.1 나의 방향성
파생변수의 경우 나는 기존 변수들을 조합해서 부족한 정보(결측치가 많음)를 해결할 수 있는 방안이 있을까하여 다시 전처리 된 데이터 들을 모두 뜯어보며 특정 패턴이 있을까 마이닝을 해보았다. 코드는 아래와 같다.

https://github.com/LWH4Data/Projects/blob/main/LG%20Aimers%204%EA%B8%B0/%EC%A0%84%EC%B2%98%EB%A6%AC%EB%90%9C%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%A7%88%EC%9D%B4%EB%8B%9D.R

결과적으로 영업 전환(target 변수)이 True인 경우와 False인 경우 근소한 패턴의 차이를 보이는 변수들은 몇 개 찾았지만 테스트 결과 성능 부분에서 개선은 없었다. 대표적인 예를 들면 영업 전환이 True인 경우 customer_idx(고객 id)의 변수 값이 중앙값에 밀집되어 있었다. 시각 자료는 다음과 같다. 

![[Pasted image 20240313063628.png|400]]

위와 같이 영업 전환이 True인 데이터는 customer_idx가 중앙값에 밀집되어 있음을 확인할 수 있었다. 따라서 다음과 같은 점을 고려하여 전처리를 수행하였다.

> - customer_idx는 연속형 변수이다. Tree 모델에서 연속형 변수는 분류 기준으로 선정됨에 있어 범주형 변수보다 우선 순위가 높다.
> - 따라서 customer_idx를 범주화한다면 연속형 변수로 인한 우위를 제거할 수 있으며 결과적으로 과적합을 방지함과 동시에 성능의 개선이 예상된다.

아쉽게도 결과적으로는 성능이 개선되지는 않았다. 과적합을 방지했는가에 관해서는 후술 하겠지만 이미 우리 팀의 모델은 과적합에 잘 대응되었다 판단되어 큰 의미가 없었을 것이라 생각한다. 

다른 변수 또한 위와 같이 패턴을 찾고 전처리를 수행해 보았지만 성능이 크게 변화하는 경우는 없었다. 

> 여러 시도를 해 본다는 점에서는 긍정적이다. 그러나 아마도 변수 중요도가 높은 변수들이 아니었기에 성능적인 부분에서 크게 변화가 없었다 생각된다.


### 3.2.2 성능을 향상 시킨 파생변수
이 경우 다른 팀원 분이 생성한 파생변수 이다. 아마 여러 시도를 해보신 것 같은데 포기하지 않고 결과를 내신 것도 놀라웠으며 아이디어 또한 놀라웠다. 

> 부족한 정보(결측치가 많음)를 처리하는 것이 중요하다 생각하고 있던 중 이 부분을 잘 보완해주는 파생변수를 생성해 주셨다. 

